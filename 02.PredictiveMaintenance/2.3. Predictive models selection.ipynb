{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea312817",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 2.3. Predictive Model Selection\n",
    "\n",
    "Module: Artificial Intelligence for Aviation Engineering\n",
    "\n",
    "Instructor: prof. Dmitry Pavlyuk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069faf60",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Statistical Model: loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d97d72",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Statistical model: loss function\n",
    "\n",
    "In order to quantify how well a model performs, we define a loss or error function. A common loss function for quantitative outcomes is the Mean Squared Error (MSE):\n",
    "\n",
    "$$\n",
    "\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "The quantity $|y_i - \\hat{y}_i|$ is called a residual and measures the error at the $i$-th prediction.\n",
    "\n",
    "\n",
    "Alternatively, we can get the root of MSE, RMSE:\n",
    "\n",
    "$$\n",
    "\\text{RMSE}  = \\sqrt{\\text{MSE}}\n",
    "$$\n",
    "\n",
    "Alternatively, we can compare with variance of the response and construct the coefficient of determination:\n",
    "\n",
    "$$\n",
    "R^2 = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2} {\\sum_{i=1}^{n} (y_i - \\bar{y}_i)^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bcc4f2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Toy example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3235794f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5  6  7  8   9\n",
       "x  1  2  3  4  5  6  7  8  9  10\n",
       "y  2  2  4  3  5  7  7  5  9   8"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "x_train = np.array(range(1,11))\n",
    "y_train = np.array([2, 2, 4, 3, 5, 7, 7, 5, 9, 8])\n",
    "data = pd.DataFrame({'x': x_train, 'y': y_train})\n",
    "data.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888cad3e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Models: kNN, Linear regression, Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c14f3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "\n",
    "knn_1 = KNeighborsRegressor(n_neighbors=1)\n",
    "knn_1.fit(data[[\"x\"]], data[[\"y\"]])\n",
    "\n",
    "knn_2 = KNeighborsRegressor(n_neighbors=2)\n",
    "knn_2.fit(data[[\"x\"]], data[[\"y\"]])\n",
    "\n",
    "knn_3 = KNeighborsRegressor(n_neighbors=3)\n",
    "knn_3.fit(data[[\"x\"]], data[[\"y\"]])\n",
    "\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(data[[\"x\"]], data[[\"y\"]])\n",
    "\n",
    "tree = DecisionTreeRegressor(max_depth=3)\n",
    "tree.fit(data[[\"x\"]], data[\"y\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e707ed",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Models: RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "820e3fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-NN regression:\tRMSE=0.000, \t\t        R2=1.000\n",
      "2-NN regression:\tRMSE=0.922, \t\t        R2=0.847\n",
      "3-NN regression:\tRMSE=1.049, \t\t        R2=0.802\n",
      "Linear regression:\tRMSE=1.025, \t\t        R2=0.811\n",
      "Decision Tree  :\tRMSE=0.516, \t\t        R2=0.952\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "models = {\n",
    "    \"1-NN regression\": knn_1,\n",
    "    \"2-NN regression\": knn_2,\n",
    "    \"3-NN regression\": knn_3,\n",
    "    \"Linear regression\": linear_model,\n",
    "    \"Decision Tree  \": tree\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(data[['x']],data[['y']])\n",
    "    print(f\"{name}:\\tRMSE={np.sqrt(mean_squared_error(data[['y']] , model.predict(data[['x']]))):.3f}, \\t\\t\\\n",
    "        R2={r2_score(data[['y']] , model.predict(data[['x']])):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be22b4a",
   "metadata": {},
   "source": [
    "__Question:__ Is this a good idea to choose the best model using $RMSE$ or $R^2$ for our sample _x_?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5215da8b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Models: Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53d5af1",
   "metadata": {},
   "source": [
    "Overfitting occurs when a model becomes overly complex, capturing random noise in the observations instead of the true relationship between the predictors and the response.\n",
    "Overfitting can occur when:\n",
    "- too flexible model\n",
    "- too many model parameters\n",
    "\n",
    "A sign of overfitting may be a high training $R^2$ or low $RMSE$, accompanied by unexpectedly poor performance on testing data.\n",
    "\n",
    "Note: There is no definitive test for overfitting, nor is there a foolproof method to prevent it. Instead, a combination of techniques can be employed to mitigate overfitting and various methods can be used to detect it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1610bc",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Models: Train/Test split\n",
    "\n",
    "The train-test split is a fundamental technique used in machine learning to evaluate the performance of a model. It involves dividing a dataset into two distinct subsets: one for training the model and one for testing its performance on unseen data.\n",
    "\n",
    "Purpose\n",
    "- To assess how well a machine learning model generalizes to new, unseen data.\n",
    "- To avoid overfitting by ensuring the model is not evaluated on the same data it was trained on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2851f0b5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Models: Train/Test split\n",
    "\n",
    "Procedure\n",
    "- Divide the Dataset: The dataset is split into two parts:\n",
    "  - Training Set: Used to train the model.\n",
    "  - Test Set: Used to evaluate the model's performance after training.\n",
    "  - A common practice is to allocate 70-80% of the data for training and 20-30% for testing.\n",
    "- Randomization: It's important to randomize the split to ensure that both subsets represent the overall dataset well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95235db6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Models: Train/Test split\n",
    "\n",
    "Advantages\n",
    "- Simple and easy to implement.\n",
    "- Provides a quick estimate of model performance on unseen data.\n",
    "\n",
    "Disadvantages\n",
    "- Depending on the random split, the results can vary significantly. A single split might not capture the model's performance accurately.\n",
    "- If the dataset is small, a significant portion of data is set aside for testing, which may lead to less reliable performance estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf596160",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Models: Train/Test split illustration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6377422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-NN regression:\tRMSE=1.633, \t        R2=-0.714\n",
      "2-NN regression:\tRMSE=1.443, \t        R2=-0.339\n",
      "3-NN regression:\tRMSE=1.610, \t        R2=-0.667\n",
      "Linear regression:\tRMSE=1.210, \t        R2=0.058\n",
      "Decision Tree  :\tRMSE=1.633, \t        R2=-0.714\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train , x_test , y_train , y_test  = train_test_split(data[[\"x\"]], data['y'], test_size=0.3)\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(x_train,y_train)\n",
    "    print(f\"{name}:\\tRMSE={np.sqrt(mean_squared_error(y_test , model.predict(x_test))):.3f}, \\t\\\n",
    "        R2={r2_score(y_test , model.predict(x_test)):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f662ae03",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Models: Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabf807f",
   "metadata": {},
   "source": [
    "Cross-validation is a statistical technique used to assess the generalization performance of a model. It helps to mitigate issues like overfitting by ensuring that the model performs well on unseen data.\n",
    "Purpose\n",
    "- To estimate how well a model will generalize to an independent dataset.\n",
    "- To identify potential issues like overfitting or underfitting.\n",
    "\n",
    "Steps in Cross-Validation\n",
    "- Split the Dataset: Divide the dataset into training and testing sets (if applicable).\n",
    "- Select 𝑘: Choose the number of folds for K-Fold cross-validation.\n",
    "- ain and validate: For each fold, train the model on k−1 folds and validate it on the remaining fold.\n",
    "- calculate metrics: Collect performance metrics (e.g., accuracy, MSE) for each fold.\n",
    "- average the results: Compute the mean of the metrics across all folds to assess the model's performance.\n",
    "\n",
    "Advantages\n",
    "- Provides a better estimate of model performance than a single train-test split.\n",
    "- Helps in hyperparameter tuning and model selection.\n",
    "\n",
    "Disadvantages\n",
    "- Computationally intensive, especially for large datasets and complex models.\n",
    "- Can still lead to overfitting if not done carefully"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b05fa28",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Models: Cross-validation illustration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2103e40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-NN regression:\tR2=0.397\n",
      "2-NN regression:\tR2=0.575\n",
      "3-NN regression:\tR2=0.146\n",
      "Linear regression:\tR2=0.430\n",
      "Decision Tree  :\tR2=-1.537\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score \n",
    "\n",
    "kf = KFold(n_splits=2, shuffle=True)\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, data[[\"x\"]], data[\"y\"], cv=kf, scoring='r2')\n",
    "    print(f\"{name}:\\tR2={np.mean(scores):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f0c783",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Models: Repeated sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3de2480e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-NN regression:\tR2=-1.460\n",
      "2-NN regression:\tR2=-4.423\n",
      "3-NN regression:\tR2=-1.941\n",
      "Linear regression:\tR2=-0.627\n",
      "Decision Tree  :\tR2=-0.896\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "kf = ShuffleSplit(n_splits=10, test_size=0.2)\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, data[[\"x\"]], data[\"y\"], cv=kf, scoring='r2')\n",
    "    print(f\"{name}:\\tR2={np.mean(scores):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab56056",
   "metadata": {
    "id": "aab56056",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Thank you"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
